// ğŸ¤– Robots.txt avanzado para control SEO
// ConfiguraciÃ³n optimizada para Google Search Console

const BASE_URL = process.env.NEXT_PUBLIC_SITE_URL || "https://nex-v.com";

export async function GET() {
  const robotsTxt = `# ğŸ¤– Directivas para rastreadores web
# Ãšltima actualizaciÃ³n: ${new Date().toISOString()}

# ğŸŒ Todos los bots amigables pueden acceder
User-agent: *
Allow: /
Disallow: /api/
Disallow: /admin/
Disallow: /private/
Disallow: /*?*

# ğŸš« Bloquear bots de scraping y IA no autorizados
User-agent: GPTBot
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: ClaudeBot
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Bytespider
Disallow: /

# ğŸ“± OptimizaciÃ³n para dispositivos mÃ³viles
User-agent: Googlebot-Mobile
Allow: /

# ğŸ–¼ï¸ OptimizaciÃ³n para imÃ¡genes
User-agent: Googlebot-Image
Allow: /

# ğŸµ OptimizaciÃ³n para videos
User-agent: Googlebot-Video
Allow: /

# ğŸ“° OptimizaciÃ³n para noticias
User-agent: Googlebot-News
Allow: /

# ğŸ” Sitemap principal
Sitemap: ${BASE_URL}/sitemap.xml

# ğŸ“Š EstadÃ­sticas de rastreo
# Puedes aÃ±adir aquÃ­ directivas especÃ­ficas si lo necesitas
# Ejemplo: Crawl-delay: 10
`;

  return new Response(robotsTxt, {
    headers: {
      "Content-Type": "text/plain",
      "Cache-Control": "public, max-age=86400", // Cache 24 horas
    },
  });
}